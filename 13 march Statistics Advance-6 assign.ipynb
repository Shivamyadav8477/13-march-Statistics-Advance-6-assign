{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9c7854-61d4-40bb-aa4a-980e87e2c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d5a15-2801-47ee-ade2-c4d746876879",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means between two or more groups to determine whether there are statistically significant differences among them. To apply ANOVA and interpret the results correctly, certain assumptions must be met. These assumptions are essential for the validity of ANOVA results. Here are the key assumptions for using ANOVA and examples of violations that can impact the validity of the results:\n",
    "\n",
    "1. **Independence of Observations**:\n",
    "   - **Assumption**: The observations within each group or treatment level are independent of each other.\n",
    "   - **Violation**: If observations within a group are correlated, it can lead to incorrect standard error estimates and, consequently, incorrect p-values. For example, in a longitudinal study, repeated measures on the same subjects over time may violate this assumption.\n",
    "\n",
    "2. **Homogeneity of Variance (Homoscedasticity)**:\n",
    "   - **Assumption**: The variance of the dependent variable should be roughly equal across all groups.\n",
    "   - **Violation**: Heteroscedasticity, where the variances in different groups are significantly different, can lead to unreliable F-statistics and p-values. For instance, if one group has much larger variances than others, it may violate this assumption.\n",
    "\n",
    "3. **Normality of Residuals**:\n",
    "   - **Assumption**: The residuals (the differences between observed values and predicted values) for each group should follow a normal distribution.\n",
    "   - **Violation**: Departures from normality can affect the validity of ANOVA results. Non-normality can lead to incorrect p-values and confidence intervals. Outliers, skewness, or heavy-tailed distributions are examples of violations.\n",
    "\n",
    "4. **Independence of Groups**:\n",
    "   - **Assumption**: The different groups or treatment levels should be independent of each other.\n",
    "   - **Violation**: If there is any dependency or interaction between groups, it can impact the validity of ANOVA results. For example, if there is contamination between groups in an experimental design, the assumption may be violated.\n",
    "\n",
    "5. **Equal Sample Sizes (for One-way ANOVA)**:\n",
    "   - **Assumption**: In one-way ANOVA, it is assumed that the sample sizes for all groups are equal.\n",
    "   - **Violation**: Unequal sample sizes can affect the interpretation of results. Adjustments may be necessary when sample sizes are significantly different.\n",
    "\n",
    "6. **Random Sampling**:\n",
    "   - **Assumption**: The data should be obtained through random sampling to ensure that the sample is representative of the population of interest.\n",
    "   - **Violation**: If the sample is not randomly selected, the results may not be generalizable to the population.\n",
    "\n",
    "7. **Interval or Ratio Data**:\n",
    "   - **Assumption**: ANOVA assumes that the dependent variable is measured on an interval or ratio scale.\n",
    "   - **Violation**: If the dependent variable is nominal or ordinal, ANOVA is not appropriate. Using ANOVA with non-interval or non-ratio data can lead to incorrect results.\n",
    "\n",
    "It's important to note that while ANOVA is robust to some violations of these assumptions, particularly with larger sample sizes, severe violations can compromise the validity of the analysis. In such cases, alternative statistical techniques or transformations of the data may be considered. Additionally, diagnostic tests, such as residual plots and normality tests, can help assess the assumptions' validity in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073001d2-a062-4647-9c06-72ddd602ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e02cb-5fa3-48a4-8c98-6266a0d02137",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means between two or more groups or treatments. There are three main types of ANOVA, each designed for specific situations:\n",
    "\n",
    "1. **One-Way ANOVA**:\n",
    "   - **Situation**: One-way ANOVA is used when you have one independent variable (categorical) with three or more levels or groups, and you want to determine if there are any statistically significant differences in the means of a continuous dependent variable among these groups.\n",
    "   - **Example**: You want to compare the average test scores of students from three different schools to see if there are significant differences in performance.\n",
    "\n",
    "2. **Two-Way ANOVA**:\n",
    "   - **Situation**: Two-way ANOVA is used when you have two independent variables (factors) that can be categorical or continuous, and you want to examine their individual and interactive effects on a continuous dependent variable.\n",
    "   - **Example**: You are studying the effect of both a drug (Factor A: Drug A, Drug B) and a dosage level (Factor B: Low, Medium, High) on patients' blood pressure. Two-way ANOVA helps you assess the main effects of the drug and dosage level and their interaction on blood pressure.\n",
    "\n",
    "3. **Repeated Measures ANOVA**:\n",
    "   - **Situation**: Repeated measures ANOVA, also known as within-subjects ANOVA, is used when you have one group of subjects (or items) that are measured under different conditions or at multiple time points. It is suitable for situations where the same subjects are used in all treatment conditions.\n",
    "   - **Example**: You are testing the effect of a new exercise program on fitness levels, and you measure the fitness of the same individuals before and after the program. Repeated measures ANOVA helps you assess if there are statistically significant differences in fitness levels across the different measurement times.\n",
    "\n",
    "Each type of ANOVA addresses different research questions and experimental designs. Choosing the appropriate type of ANOVA depends on the number of independent variables, their nature (categorical or continuous), and the experimental design (between-subjects or within-subjects). It's important to select the right ANOVA technique to ensure that the analysis is appropriate for your research objectives and data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b4ae1-bc91-4ae3-9a48-6833a9316ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e994b6-52a7-4fb8-9e29-d79013867509",
   "metadata": {},
   "outputs": [],
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) is a fundamental concept that helps us understand how the total variation in a dataset can be decomposed into different components. These components represent the sources of variation in an ANOVA analysis and provide insights into the contributions of various factors to the variability of the dependent variable. Understanding this concept is crucial for several reasons:\n",
    "\n",
    "1. **Identifying Sources of Variation**: ANOVA helps us identify and quantify the sources of variation in a dataset. By partitioning the total variance into different components, we can determine how much of the variation is due to different factors, such as treatment effects, random error, or interactions between factors.\n",
    "\n",
    "2. **Hypothesis Testing**: ANOVA allows us to test hypotheses about the equality of group means. By understanding the partitioning of variance, we can assess whether the observed differences among group means are statistically significant or if they could have occurred due to random variability.\n",
    "\n",
    "3. **Interpreting Results**: Understanding the partitioned variance components helps in interpreting the results of ANOVA. For example, if a significant portion of the total variance is attributed to treatment effects, it suggests that the independent variable (factor) has a substantial impact on the dependent variable.\n",
    "\n",
    "4. **Effect Size**: The partitioned variance components can be used to calculate effect sizes, which provide a measure of the practical significance of observed differences. Effect sizes help researchers assess the magnitude of treatment effects beyond statistical significance.\n",
    "\n",
    "5. **Study Design and Improvement**: By knowing the sources of variation, researchers can design experiments more effectively. For example, if a large portion of the total variance is due to random error, researchers may consider ways to reduce this error, such as increasing sample size or improving measurement precision.\n",
    "\n",
    "The partitioning of variance in ANOVA typically includes the following components:\n",
    "\n",
    "- **Total Variation (Total Sum of Squares, SST)**: This represents the total variability in the data without regard to groupings. It measures how much the data points vary from the overall mean.\n",
    "\n",
    "- **Between-Group Variation (Between-Group Sum of Squares, SSB)**: This represents the variation among the group means. It measures how much the group means differ from each other.\n",
    "\n",
    "- **Within-Group Variation (Within-Group Sum of Squares, SSW)**: This represents the variation within each group. It measures how much individual data points within each group deviate from their group mean.\n",
    "\n",
    "- **Error Variation (Error Sum of Squares, SSE)**: This is synonymous with the within-group variation and represents the random error or residual variation that cannot be explained by the factors in the model.\n",
    "\n",
    "Understanding how these components relate to each other and contribute to the total variance helps researchers make informed decisions about the significance of their findings, the appropriateness of their experimental design, and the practical implications of their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6410a1-852e-45a1-87f8-ab423d454cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e41d7-d306-4d26-823d-b4c2e3f1fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a one-way ANOVA, you can calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) using Python. These components help you understand the variability in the data and assess the significance of group differences. Here's how you can calculate them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7494fc-2ff0-40ae-bf59-fdcedbede009",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total Sum of Squares (SST):\n",
    "\n",
    "SST measures the total variability in the data without regard to groupings. It quantifies how much the data points vary from the overall mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9744744a-4cfd-4580-9edb-df7150746f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data for each group\n",
    "group1 = np.array([25, 30, 35, 40, 45])\n",
    "group2 = np.array([20, 22, 24, 26, 28])\n",
    "group3 = np.array([10, 15, 20, 25, 30])\n",
    "\n",
    "# Combine all data into one array\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate SST\n",
    "sst = np.sum((all_data - overall_mean) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b41cb-1234-4843-99c4-2cac7911c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Explained Sum of Squares (SSE):\n",
    "\n",
    "SSE measures the variation among the group means. It quantifies how much the group means differ from each oth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c787c218-a6ce-49cc-a4c1-61ac2048101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of each group\n",
    "mean_group1 = np.mean(group1)\n",
    "mean_group2 = np.mean(group2)\n",
    "mean_group3 = np.mean(group3)\n",
    "\n",
    "# Calculate SSE\n",
    "sse = len(group1) * (mean_group1 - overall_mean) ** 2 + \\\n",
    "      len(group2) * (mean_group2 - overall_mean) ** 2 + \\\n",
    "      len(group3) * (mean_group3 - overall_mean) ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ebcd35-15e8-49a2-8a1b-3438adc12307",
   "metadata": {},
   "outputs": [],
   "source": [
    "Residual Sum of Squares (SSR):\n",
    "\n",
    "SSR, also known as Error Sum of Squares, measures the variation within each group that cannot be explained by group differences. It represents random error or unexplained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07f8431-5e94-49ab-bd5b-046ad9bb4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of squared deviations within each group\n",
    "ssr_group1 = np.sum((group1 - mean_group1) ** 2)\n",
    "ssr_group2 = np.sum((group2 - mean_group2) ** 2)\n",
    "ssr_group3 = np.sum((group3 - mean_group3) ** 2)\n",
    "\n",
    "# Calculate SSR\n",
    "ssr = ssr_group1 + ssr_group2 + ssr_group3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465e304-7013-466f-b349-447c859d1819",
   "metadata": {},
   "outputs": [],
   "source": [
    "After calculating SST, SSE, and SSR, you can use these values to compute the F-statistic and perform hypothesis tests to determine whether there are significant differences among the group means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f1fc5-96d2-4a1f-aa3c-e636dfe56ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b6a7a-8b05-4e43-9248-bfe0825c66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a two-way ANOVA, you can calculate the main effects and interaction effects using Python by first fitting an appropriate statistical model and then extracting the relevant components. The main effects represent the effects of each independent variable (factor), and the interaction effect represents how the two independent variables interact with each other. Here's how you can calculate these effects using the Python library statsmodels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96477401-e5ff-4012-865d-a5bd55e0e192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/compat.py\", line 36, in call_and_wrap_exc\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 169, in eval\n",
      "    return eval(code, {}, VarLookupDict([inner_namespace]\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 52, in __getitem__\n",
      "    return d[key]\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 52, in __getitem__\n",
      "    return d[key]\n",
      "TypeError: 'ellipsis' object is not subscriptable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_7201/451250925.py\", line 10, in <module>\n",
      "    model = ols('Outcome ~ FactorA * FactorB', data=data).fit()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py\", line 200, in from_formula\n",
      "    tmp = handle_formula_data(data, None, formula, depth=eval_env,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/statsmodels/formula/formulatools.py\", line 66, in handle_formula_data\n",
      "    result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/highlevel.py\", line 309, in dmatrices\n",
      "    (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/highlevel.py\", line 164, in _do_highlevel_design\n",
      "    design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/highlevel.py\", line 66, in _try_incr_builders\n",
      "    return design_matrix_builders([formula_like.lhs_termlist,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/build.py\", line 693, in design_matrix_builders\n",
      "    cat_levels_contrasts) = _examine_factor_types(all_factors,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/build.py\", line 443, in _examine_factor_types\n",
      "    value = factor.eval(factor_states[factor], data)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 568, in eval\n",
      "    return self._eval(memorize_state[\"eval_code\"],\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 551, in _eval\n",
      "    return call_and_wrap_exc(\"Error evaluating factor\",\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/compat.py\", line 43, in call_and_wrap_exc\n",
      "    exec(\"raise new_exc from e\")\n",
      "  File \"<string>\", line 1, in <module>\n",
      "patsy.PatsyError: Error evaluating factor: TypeError: 'ellipsis' object is not subscriptable\n",
      "    Outcome ~ FactorA * FactorB\n",
      "                        ^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 878, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 801, in format_exception_as_a_whole\n",
      "    if r.frame.f_locals.get(\"__tracebackhide__\", 0) and i != lastrecord:\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 70, in get\n",
      "    return self[key]\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 52, in __getitem__\n",
      "    return d[key]\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 52, in __getitem__\n",
      "    return d[key]\n",
      "TypeError: 'ellipsis' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with your data, including the two independent variables and the dependent variable.\n",
    "# Replace 'data' with your actual dataset.\n",
    "# The two independent variables are 'FactorA' and 'FactorB', and the dependent variable is 'Outcome'.\n",
    "data = ...\n",
    "\n",
    "# Fit a two-way ANOVA model with interaction\n",
    "model = ols('Outcome ~ FactorA * FactorB', data=data).fit()\n",
    "\n",
    "# Calculate main effects and interaction effect\n",
    "main_effect_A = model.params['FactorA']\n",
    "main_effect_B = model.params['FactorB']\n",
    "interaction_effect = model.params['FactorA:FactorB']\n",
    "\n",
    "# Print the main effects and interaction effect\n",
    "print(\"Main Effect of Factor A:\", main_effect_A)\n",
    "print(\"Main Effect of Factor B:\", main_effect_B)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a8222-d8a6-4eee-b559-b0af73dd95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "Replace 'FactorA', 'FactorB', and 'Outcome' with the actual variable names in your dataset.\n",
    "The ols function is used to specify the model formula, which includes the main effects of 'FactorA' and 'FactorB' as well as their interaction ('FactorA * FactorB').\n",
    "The .fit() method fits the model to the data.\n",
    "The main effects are extracted from the model parameters using model.params.\n",
    "The interaction effect is also extracted from the model parameters.\n",
    "By fitting this two-way ANOVA model and extracting the main and interaction effects, you can assess the impact of each factor and their interaction on the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff94bbd-de28-435a-8f3b-f480f45fe6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640fa29-8d2e-4a7f-90c8-e31f7cbddb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "When you conduct a one-way ANOVA and obtain an F-statistic of 5.23 with a p-value of 0.02, you are testing the hypothesis that the means of the groups are equal. Here's how to interpret these results:\n",
    "\n",
    "1. **Null Hypothesis (\\(H_0\\))**: The null hypothesis in a one-way ANOVA typically states that there are no significant differences in the means of the groups. Mathematically, it can be expressed as:\n",
    "   \n",
    "   \\(H_0\\): The population means of all groups are equal.\n",
    "\n",
    "2. **Alternative Hypothesis (\\(H_a\\))**: The alternative hypothesis suggests that at least one group mean is different from the others. It can be expressed as:\n",
    "   \n",
    "   \\(H_a\\): At least one population mean is different from the others.\n",
    "\n",
    "3. **F-Statistic**: The F-statistic is a test statistic that measures the ratio of the explained variation (between-group variation) to the unexplained variation (within-group variation). In simple terms, it tells you whether the differences among the group means are statistically significant.\n",
    "\n",
    "4. **P-Value**: The p-value associated with the F-statistic represents the probability of observing the obtained F-statistic (or a more extreme value) under the assumption that the null hypothesis is true. A low p-value suggests that the observed differences in group means are unlikely to have occurred by random chance alone.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- In your case, the F-statistic is 5.23, which indicates that there is some variation among the group means.\n",
    "- The p-value of 0.02 is less than the commonly chosen significance level of 0.05 (5%). This means that the probability of observing such differences in group means by random chance alone is only 2%.\n",
    "\n",
    "Based on these results:\n",
    "\n",
    "- **Conclusion**: You can reject the null hypothesis (\\(H_0\\)) because the p-value is less than 0.05.\n",
    "\n",
    "- **Interpretation**: There are statistically significant differences among the group means. In other words, at least one group mean is different from the others. However, the ANOVA test itself doesn't tell you which specific group means are different; it only tells you that there is a difference somewhere among the groups.\n",
    "\n",
    "- **Further Analysis**: To determine which specific group means are different from each other, you may need to perform post-hoc tests (e.g., Tukey's HSD test or pairwise t-tests with adjustments for multiple comparisons).\n",
    "\n",
    "In summary, your one-way ANOVA suggests that there are significant differences among the groups, but to identify which groups are different, additional post-hoc tests are typically necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd897ff6-b277-4f9f-b207-9b9195bf2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344613a0-aa42-4af4-bd6f-8595d4bc47c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Handling missing data in a repeated measures ANOVA is an important aspect of data analysis. Missing data can occur when some observations are missing for one or more time points or levels of the repeated measures factor. There are several methods to handle missing data, and the choice of method can impact the results and conclusions of the analysis. Here are some common methods for handling missing data in a repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "1. **Listwise Deletion (Complete Case Analysis)**:\n",
    "   - **Method**: This approach removes cases (subjects or observations) with missing data from the analysis. Only complete cases with data for all time points or levels are used.\n",
    "   - **Consequences**:\n",
    "     - Pros: Simple to implement.\n",
    "     - Cons: Reduces sample size, potentially leading to loss of statistical power and biased results if missing data is not completely at random (MCAR). Also, if a large portion of data is missing, it can significantly reduce the sample size.\n",
    "\n",
    "2. **Mean Imputation**:\n",
    "   - **Method**: Replace missing values with the mean of the available values for that variable.\n",
    "   - **Consequences**:\n",
    "     - Pros: Easy to implement and does not reduce the sample size.\n",
    "     - Cons: Can lead to biased estimates and underestimation of variance if data is not MCAR. It reduces variability and may obscure actual patterns in the data.\n",
    "\n",
    "3. **Linear Interpolation**:\n",
    "   - **Method**: Estimate missing values by linearly interpolating between adjacent time points or levels.\n",
    "   - **Consequences**:\n",
    "     - Pros: Preserves the temporal or sequential structure of data.\n",
    "     - Cons: Requires a continuous time scale, may introduce noise, and assumes linear relationships between measurements, which may not always be appropriate.\n",
    "\n",
    "4. **Last Observation Carried Forward (LOCF)**:\n",
    "   - **Method**: Replace missing values with the last observed value for that subject.\n",
    "   - **Consequences**:\n",
    "     - Pros: Preserves temporal order and can be useful in certain clinical settings.\n",
    "     - Cons: Assumes that the last observation is a good representation of the missing values, which may not always be true. Can lead to biased estimates if there is substantial missing data.\n",
    "\n",
    "5. **Multiple Imputation**:\n",
    "   - **Method**: Generate multiple imputed datasets, each with different imputed values for missing data, and perform the analysis separately on each dataset. Combine results to account for uncertainty.\n",
    "   - **Consequences**:\n",
    "     - Pros: Provides unbiased estimates and valid standard errors when data is missing at random (MAR). Handles missing data more appropriately than other methods.\n",
    "     - Cons: More complex and computationally intensive than other methods.\n",
    "\n",
    "6. **Model-Based Imputation**:\n",
    "   - **Method**: Use statistical models to impute missing values based on observed data and relationships within the dataset.\n",
    "   - **Consequences**:\n",
    "     - Pros: Can provide accurate imputations when the model assumptions are met.\n",
    "     - Cons: Requires careful model selection and validation. Model misspecification can lead to biased results.\n",
    "\n",
    "The choice of method should be guided by the nature of the missing data and the assumptions underlying each method. It is essential to consider the potential biases and consequences associated with each approach and to conduct sensitivity analyses to assess the robustness of results to different imputation methods. Multiple imputation is generally considered a robust approach, but it requires more effort and resources to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c54d089-6f83-4427-bb55-1fe5cd08d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461858f6-0394-443c-90bf-9c42de8a3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Post-hoc tests are used in the context of Analysis of Variance (ANOVA) to make pairwise comparisons between group means when the ANOVA results indicate that there are significant differences among the groups. Common post-hoc tests include Tukey's Honestly Significant Difference (HSD) test, Bonferroni correction, Scheffé's test, and Dunnett's test, among others. The choice of post-hoc test depends on factors such as the number of groups, the nature of the data, and the desired level of control over Type I errors (false positives). Here's a brief overview of some common post-hoc tests and when to use them:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD) Test**:\n",
    "   - **Use**: Tukey's HSD test is suitable when you have three or more groups and want to compare all possible pairs of means. It controls the familywise error rate, making it a conservative choice.\n",
    "   - **Example**: You are comparing the test scores of students from five different schools, and the ANOVA results suggest there are significant differences among the schools. Tukey's HSD can help you identify which specific pairs of schools have significantly different mean scores.\n",
    "\n",
    "2. **Bonferroni Correction**:\n",
    "   - **Use**: Bonferroni correction is a conservative method used when making multiple pairwise comparisons after ANOVA. It controls the overall Type I error rate but tends to be less powerful than Tukey's HSD.\n",
    "   - **Example**: You are conducting pairwise comparisons of means for five different treatment groups. Bonferroni correction can be used when you want to maintain a strict control over the familywise error rate.\n",
    "\n",
    "3. **Scheffé's Test**:\n",
    "   - **Use**: Scheffé's test is a more robust but less conservative method for making pairwise comparisons after ANOVA. It is used when you have three or more groups and want to control the familywise error rate more flexibly.\n",
    "   - **Example**: You are comparing the performance of different marketing strategies in four regions. Scheffé's test can be helpful when you suspect that the group variances may not be equal.\n",
    "\n",
    "4. **Dunnett's Test**:\n",
    "   - **Use**: Dunnett's test is used when you have one control group and several treatment groups, and you want to compare each treatment group to the control group.\n",
    "   - **Example**: You are testing the effectiveness of three different drugs compared to a placebo (control group). Dunnett's test can help you determine which drug(s) have a significantly different effect compared to the control.\n",
    "\n",
    "5. **Holm-Bonferroni Method**:\n",
    "   - **Use**: The Holm-Bonferroni method is a modified Bonferroni correction that adjusts the p-values in a way that allows for a less stringent control of the familywise error rate while still controlling Type I errors.\n",
    "   - **Example**: You are conducting multiple pairwise comparisons in a study, and you want to balance the trade-off between Type I errors and statistical power. The Holm-Bonferroni method can be used for this purpose.\n",
    "\n",
    "6. **Games-Howell Test**:\n",
    "   - **Use**: The Games-Howell test is a post-hoc test suitable when group variances are unequal. It is more robust than Tukey's HSD in such cases.\n",
    "   - **Example**: You are comparing the performance of different products across regions, and the variances of sales data are significantly different between regions. The Games-Howell test can be used to account for unequal variances.\n",
    "\n",
    "In summary, the choice of a post-hoc test depends on the specific research question, the nature of the data, and the desired control over Type I errors. It is essential to select a post-hoc test that is appropriate for your experimental design to make valid and meaningful pairwise comparisons after obtaining significant results from ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b87745-2a33-430a-aabd-5f7e9981aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e46d2-d07d-41d9-9647-dc5e664de001",
   "metadata": {},
   "outputs": [],
   "source": [
    "To conduct a one-way ANOVA in Python and determine if there are any significant differences between the mean weight loss of three diets (A, B, and C), you can use the scipy.stats library. Here's how you can perform the analysis and interpret the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdca11f9-34e0-42e7-b87b-aad46aba609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 295.32861400894234\n",
      "p-value: 3.239745074836262e-52\n",
      "The p-value is less than the significance level, so we reject the null hypothesis.\n",
      "There is a significant difference in mean weight loss among the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data for weight loss in each diet group\n",
    "diet_A = np.array([2.3, 1.8, 3.0, 2.5, 2.9, 1.5, 2.1, 2.7, 1.8, 2.0,\n",
    "                   2.8, 2.2, 2.6, 1.9, 2.4, 2.7, 2.0, 1.6, 2.3, 2.1,\n",
    "                   2.4, 1.7, 2.5, 2.9, 2.2, 2.8, 2.3, 1.9, 2.6, 2.4,\n",
    "                   2.1, 2.7, 2.0, 2.5, 1.8, 2.2, 2.3, 1.7, 2.4, 2.9,\n",
    "                   2.6, 2.1, 2.8, 1.6, 2.7, 2.5, 1.8, 2.0, 2.3, 2.4])\n",
    "\n",
    "diet_B = np.array([1.2, 1.5, 1.8, 1.3, 1.6, 1.9, 1.7, 1.4, 1.1, 1.3,\n",
    "                   1.5, 1.2, 1.6, 1.4, 1.7, 1.8, 1.9, 1.3, 1.5, 1.1,\n",
    "                   1.2, 1.6, 1.8, 1.4, 1.7, 1.5, 1.3, 1.9, 1.2, 1.4,\n",
    "                   1.7, 1.5, 1.3, 1.8, 1.6, 1.9, 1.1, 1.4, 1.2, 1.3,\n",
    "                   1.7, 1.8, 1.6, 1.5, 1.2, 1.4, 1.9, 1.3, 1.1, 1.7])\n",
    "\n",
    "diet_C = np.array([0.8, 1.0, 0.6, 0.9, 0.7, 0.5, 1.1, 0.8, 0.7, 1.2,\n",
    "                   0.9, 0.6, 1.0, 1.1, 0.7, 0.5, 1.2, 0.8, 0.6, 1.1,\n",
    "                   0.7, 1.0, 0.9, 0.5, 1.1, 1.2, 0.8, 0.7, 0.6, 0.9,\n",
    "                   1.0, 0.5, 0.7, 1.2, 0.6, 0.9, 0.8, 0.7, 1.1, 1.0,\n",
    "                   0.5, 0.6, 0.9, 0.7, 1.2, 1.1, 0.8, 0.7, 1.0, 0.5])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Report the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The p-value is less than the significance level, so we reject the null hypothesis.\")\n",
    "    print(\"There is a significant difference in mean weight loss among the three diets.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than the significance level, so we fail to reject the null hypothesis.\")\n",
    "    print(\"There is no significant difference in mean weight loss among the three diets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6041ab7-e702-4492-bf06-e57f824f80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this example:\n",
    "\n",
    "We have weight loss data for three diet groups: A, B, and C.\n",
    "We use stats.f_oneway to perform a one-way ANOVA to test if there are any significant differences among the means of the three groups.\n",
    "The F-statistic and p-value are calculated and reported.\n",
    "We interpret the results by comparing the p-value to the significance level (alpha). If the p-value is less than alpha (0.05), we reject the null hypothesis and conclude that there is a significant difference in mean weight loss among the three diets.\n",
    "Remember that the interpretation should always be based on the context of the study and the chosen significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5978c4-c4fc-4377-bb86-09032f5274e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7031e5-9c61-4487-94f3-d51f2a5650e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "To conduct a two-way ANOVA in Python to determine if there are any main effects or interaction effects between the software programs and employee experience level, you can use the statsmodels library. Here's how you can perform the analysis and interpret the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab38d08-55f9-4eed-be25-aac50577fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/compat.py\", line 36, in call_and_wrap_exc\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 169, in eval\n",
      "    return eval(code, {}, VarLookupDict([inner_namespace]\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 52, in __getitem__\n",
      "    return d[key]\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 52, in __getitem__\n",
      "    return d[key]\n",
      "TypeError: 'ellipsis' object is not subscriptable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_7201/1103571919.py\", line 10, in <module>\n",
      "    model = ols('CompletionTime ~ C(Software) * C(Experience)', data=data).fit()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py\", line 200, in from_formula\n",
      "    tmp = handle_formula_data(data, None, formula, depth=eval_env,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/statsmodels/formula/formulatools.py\", line 66, in handle_formula_data\n",
      "    result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/highlevel.py\", line 309, in dmatrices\n",
      "    (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/highlevel.py\", line 164, in _do_highlevel_design\n",
      "    design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/highlevel.py\", line 66, in _try_incr_builders\n",
      "    return design_matrix_builders([formula_like.lhs_termlist,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/build.py\", line 693, in design_matrix_builders\n",
      "    cat_levels_contrasts) = _examine_factor_types(all_factors,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/build.py\", line 443, in _examine_factor_types\n",
      "    value = factor.eval(factor_states[factor], data)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 568, in eval\n",
      "    return self._eval(memorize_state[\"eval_code\"],\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 551, in _eval\n",
      "    return call_and_wrap_exc(\"Error evaluating factor\",\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/compat.py\", line 43, in call_and_wrap_exc\n",
      "    exec(\"raise new_exc from e\")\n",
      "  File \"<string>\", line 1, in <module>\n",
      "patsy.PatsyError: Error evaluating factor: TypeError: 'ellipsis' object is not subscriptable\n",
      "    CompletionTime ~ C(Software) * C(Experience)\n",
      "                     ^^^^^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 878, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 801, in format_exception_as_a_whole\n",
      "    if r.frame.f_locals.get(\"__tracebackhide__\", 0) and i != lastrecord:\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 70, in get\n",
      "    return self[key]\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 52, in __getitem__\n",
      "    return d[key]\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/patsy/eval.py\", line 52, in __getitem__\n",
      "    return d[key]\n",
      "TypeError: 'ellipsis' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with your data, including software programs, employee experience level, and task completion times.\n",
    "# Replace 'data' with your actual dataset.\n",
    "data = ...\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "model = ols('CompletionTime ~ C(Software) * C(Experience)', data=data).fit()\n",
    "\n",
    "# Perform the two-way ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Report the results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5ab76-557c-457b-a10b-f58d88929ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "Replace 'Software', 'Experience', and 'CompletionTime' with the actual variable names in your dataset.\n",
    "The ols function is used to specify the model formula, which includes both main effects (Software and Experience) and their interaction (Software * Experience).\n",
    "The anova_lm function is used to perform the two-way ANOVA and create an ANOVA table.\n",
    "The ANOVA table will provide F-statistics and p-values for each main effect (Software and Experience) and the interaction effect. You can interpret the results as follows:\n",
    "\n",
    "If the p-value for the Software main effect is small (typically less than 0.05), it suggests that there is a significant difference in task completion times between the software programs.\n",
    "If the p-value for the Experience main effect is small, it suggests that there is a significant difference in task completion times between novice and experienced employees.\n",
    "If the p-value for the interaction effect is small, it suggests that the effect of software programs on task completion times is different for novice and experienced employees, indicating an interaction.\n",
    "Interpretation of the results should consider the context of the study and the chosen significance level (alpha).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b66c12-7c98-409b-98d1-e83261abc099",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9d73b-f607-488c-9da6-aec454f48b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "To conduct a two-sample t-test in Python to determine if there are any significant differences in test scores between the control group (traditional teaching method) and the experimental group (new teaching method), you can use the scipy.stats library. If the results are significant, you can follow up with a post-hoc test such as Tukey's Honestly Significant Difference (HSD) test to identify which group(s) differ significantly. Here's how you can perform the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf1a8d0-053f-4faa-9897-3b71b38e16cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test Results:\n",
      "t-statistic: -1.6677351961320235\n",
      "p-value: 0.09856078338184605\n",
      "The p-value is greater than the significance level, so we fail to reject the null hypothesis.\n",
      "There is no significant difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data (replace with your actual data)\n",
    "np.random.seed(0)  # for reproducibility\n",
    "control_group_scores = np.random.normal(70, 10, 50)  # Control group scores\n",
    "experimental_group_scores = np.random.normal(75, 10, 50)  # Experimental group scores\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "# Report the t-statistic and p-value\n",
    "print(\"Two-Sample T-Test Results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The p-value is less than the significance level, so we reject the null hypothesis.\")\n",
    "    print(\"There is a significant difference in test scores between the control and experimental groups.\")\n",
    "    \n",
    "    # Perform a post-hoc test (Tukey's HSD) to identify significant group differences\n",
    "    data = pd.DataFrame({'Scores': np.concatenate((control_group_scores, experimental_group_scores)),\n",
    "                         'Group': ['Control'] * 50 + ['Experimental'] * 50})\n",
    "    tukey_results = pairwise_tukeyhsd(data['Scores'], data['Group'], alpha=alpha)\n",
    "    print(\"\\nPost-Hoc (Tukey's HSD) Test Results:\")\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print(\"The p-value is greater than the significance level, so we fail to reject the null hypothesis.\")\n",
    "    print(\"There is no significant difference in test scores between the control and experimental groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b2dc9-a3f1-4501-a59a-d05b16384fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n this code:\n",
    "\n",
    "Replace the sample data generation with your actual data for the control and experimental groups.\n",
    "We use stats.ttest_ind to perform a two-sample t-test to compare the means of the control and experimental groups.\n",
    "The t-statistic and p-value are calculated and reported.\n",
    "If the p-value is less than the chosen significance level (alpha), we reject the null hypothesis, indicating a significant difference in test scores between the groups.\n",
    "We then perform a post-hoc test (Tukey's HSD) using pairwise_tukeyhsd to identify which group(s) differ significantly from each other.\n",
    "Interpret the results based on the p-value, and if significant differences are found, the post-hoc test results will help you pinpoint which group(s) have significantly different test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9add252-0a56-46f6-91ff-0dcff42e422e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade75e50-6397-4710-831b-76d1c9051c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
